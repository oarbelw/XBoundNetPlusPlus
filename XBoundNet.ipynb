{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3035ef-f95c-4325-a1ee-23506f9fc42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, BatchNormalization, Activation, Conv2DTranspose, Add\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow_addons as tfa\n",
    "import math\n",
    "import random\n",
    "import joblib\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "original_width, original_height = 788, 510  # dimensions of original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8edb7-0589-4ea5-8af3-41174688a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear Keras/TensorFlow GPU session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Check for available GPUs\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Force TensorFlow to use the GPU if available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(\"GPU Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06cc2c-08a5-4d82-9844-e2b6636c5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, mask):\n",
    "    image = tf.cast(image, tf.float64)\n",
    "    mask = tf.cast(mask, tf.float64)\n",
    "\n",
    "    def hflip_fn():\n",
    "        return tf.image.flip_left_right(image), tf.image.flip_left_right(mask)\n",
    "\n",
    "    def vflip_fn():\n",
    "        return tf.image.flip_up_down(image), tf.image.flip_up_down(mask)\n",
    "\n",
    "    def shift_fn():\n",
    "        height = tf.shape(image)[0]\n",
    "        width = tf.shape(image)[1]\n",
    "        shift_h = tf.cast(0.1 * tf.cast(height, tf.float64), tf.int32)\n",
    "        shift_w = tf.cast(0.1 * tf.cast(width, tf.float64), tf.int32)\n",
    "        dx = tf.random.uniform([], -shift_w, shift_w + 1, dtype=tf.int32)\n",
    "        dy = tf.random.uniform([], -shift_h, shift_h + 1, dtype=tf.int32)\n",
    "        image_shifted = tfa.image.translate(image, [dx, dy])\n",
    "        mask_shifted = tfa.image.translate(mask, [dx, dy])\n",
    "        return image_shifted, mask_shifted\n",
    "\n",
    "    def rotate_fn():\n",
    "        angle = tf.random.uniform([], -20.0, 20.0) * (np.pi / 180.0)\n",
    "        image_rot = tf.cast(image, tf.float32)\n",
    "        mask_rot = tf.cast(mask, tf.float32)\n",
    "        image_rot = tfa.image.rotate(image_rot, angle, interpolation='BILINEAR')\n",
    "        mask_rot = tfa.image.rotate(mask_rot, angle, interpolation='NEAREST')\n",
    "        return tf.cast(image_rot, tf.float64), tf.cast(mask_rot, tf.float64)\n",
    "\n",
    "    def zoom_fn():\n",
    "        zoom_factor = tf.random.uniform([], 0.9, 1.1)\n",
    "        size = tf.cast(tf.shape(image)[:2], tf.float32)\n",
    "        new_size = tf.cast(zoom_factor * size, tf.int32)\n",
    "        image_zoom = tf.image.resize(image, new_size, method='bilinear')\n",
    "        mask_zoom = tf.image.resize(mask, new_size, method='nearest')\n",
    "        image_zoom = tf.image.resize_with_crop_or_pad(image_zoom, 256, 256)\n",
    "        mask_zoom = tf.image.resize_with_crop_or_pad(mask_zoom, 256, 256)\n",
    "        return tf.cast(image_zoom, tf.float64), tf.cast(mask_zoom, tf.float64)\n",
    "\n",
    "    def contrast_fn():\n",
    "        image_adj = tf.image.random_contrast(tf.cast(image, tf.float32), 0.8, 1.2)\n",
    "        return tf.cast(image_adj, tf.float64)\n",
    "\n",
    "    # Apply augmentations with tf.cond\n",
    "    image, mask = tf.cond(tf.random.uniform(()) < 0.3, hflip_fn, lambda: (image, mask))\n",
    "    image, mask = tf.cond(tf.random.uniform(()) < 0.3, vflip_fn, lambda: (image, mask))\n",
    "    image, mask = tf.cond(tf.random.uniform(()) < 0.3, shift_fn, lambda: (image, mask))\n",
    "    image, mask = tf.cond(tf.random.uniform(()) < 0.3, rotate_fn, lambda: (image, mask))\n",
    "    image, mask = tf.cond(tf.random.uniform(()) < 0.3, zoom_fn, lambda: (image, mask))\n",
    "    image = tf.cond(tf.random.uniform(()) < 0.3, contrast_fn, lambda: image)\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b6375-3e26-4ad6-b976-e5f8ef968a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    original_images = sorted(glob(os.path.join(path, \"Images\", \"*.bmp\")))\n",
    "    mask_images = sorted(glob(os.path.join(path, \"Masks\", \"*.bmp\")))\n",
    "    \n",
    "    assert len(original_images) == len(mask_images), \"Mismatch between images and masks!\"\n",
    "\n",
    "    return np.array(original_images), np.array(mask_images)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (256,256))\n",
    "    x = x/255.0    \n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (256,256))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis = -1)    \n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y, augment=False):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([256, 256, 3])\n",
    "    y.set_shape([256, 256, 1])\n",
    "\n",
    "    if augment:\n",
    "        x, y = augment_image(x, y)  # See below for function\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def tf_dataset(x, y, batch=8, augment=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(lambda a, b: tf_parse(a, b, augment=augment),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16750db0-f8bc-4ca2-bf96-70fe7e7c7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"/path/to/dataset/\"\n",
    "\n",
    "# All data\n",
    "images, masks = load_data(dataset_path)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8650e-b319-4263-8da5-9b66e10124c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Conv2DTranspose, Add, BatchNormalization,\n",
    "                                     Activation, concatenate, GlobalAveragePooling2D, Dense, Reshape, Multiply)\n",
    "\n",
    "def squeeze_excite_block(inputs, ratio=16):\n",
    "    filters = inputs.shape[-1]\n",
    "    se = GlobalAveragePooling2D()(inputs)\n",
    "    se = Dense(filters // ratio, activation='relu')(se)\n",
    "    se = Dense(filters, activation='sigmoid')(se)\n",
    "    se = Reshape((1, 1, filters))(se)\n",
    "    return Multiply()([inputs, se])\n",
    "\n",
    "def attention_gate(x, gating):\n",
    "    filters = x.shape[-1]\n",
    "    theta_x = Conv2D(filters, (1, 1), padding=\"same\")(x)\n",
    "    phi_g = Conv2D(filters, (1, 1), padding=\"same\")(gating)\n",
    "    act = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "    psi = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(act)\n",
    "    return Multiply()([x, psi])\n",
    "\n",
    "def conv_block(inputs, n_filters, kernel_size=3, strides=1):\n",
    "    x = Conv2D(n_filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def residual_se_block(inputs, n_filters):\n",
    "    x = conv_block(inputs, n_filters)\n",
    "    x = conv_block(x, n_filters)\n",
    "    x = squeeze_excite_block(x)\n",
    "    shortcut = Conv2D(n_filters, (1,1), padding='same')(inputs)\n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "def aspp_block(x, n_filters):\n",
    "    # ASPP with dilation rates 1, 6, 12, 18 (DeepLab-style)\n",
    "    conv1 = Conv2D(n_filters, 3, padding=\"same\", dilation_rate=1)(x)\n",
    "    conv6 = Conv2D(n_filters, 3, padding=\"same\", dilation_rate=6)(x)\n",
    "    conv12 = Conv2D(n_filters, 3, padding=\"same\", dilation_rate=12)(x)\n",
    "    conv18 = Conv2D(n_filters, 3, padding=\"same\", dilation_rate=18)(x)\n",
    "    x = Add()([conv1, conv6, conv12, conv18])\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def upconv_block(inputs, n_filters):\n",
    "    x = Conv2DTranspose(n_filters, 3, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def XBoundNetPP(input_shape=(256, 256, 3), n_classes=1, dropout_rate=0.2):\n",
    "    inputs = Input(input_shape)\n",
    "    filters = [32, 64, 128, 256, 512]\n",
    "    skip_connections = []\n",
    "\n",
    "    # --- Stem ---\n",
    "    x = conv_block(inputs, filters[0])\n",
    "    x = conv_block(x, filters[0])\n",
    "    #x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # --- Encoder: Residual + SE blocks ---\n",
    "    for i in range(1, len(filters)-1):\n",
    "        x = residual_se_block(x, filters[i])\n",
    "        if i >= 2:  # Only apply dropout to deeper levels\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "        skip_connections.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # --- Bottleneck with ASPP ---\n",
    "    x = aspp_block(x, filters[-1])\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # --- Decoder with Attention + SE ---\n",
    "    for i in reversed(range(len(skip_connections))):\n",
    "        x = upconv_block(x, filters[i+1])\n",
    "        g = attention_gate(skip_connections[i], x)\n",
    "        x = concatenate([x, g])\n",
    "        x = residual_se_block(x, filters[i+1])\n",
    "        if i > 0:  # Only apply dropout to deeper levels\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # --- Final Output ---\n",
    "    outputs = Conv2D(n_classes, 1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea69e5f-0a31-499a-b6a0-c300bdbf8fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = XBoundNetPP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975891f7-b21a-4d66-a48b-a1ec4123ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_predict(path):\n",
    "  x = cv2.imread(path, cv2.IMREAD_COLOR) #788x510\n",
    "  y = cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n",
    "  y = cv2.resize(y, (256,256))\n",
    "  y = y/255.0\n",
    "  x = cv2.resize(x, (256,256))\n",
    "  x = x/255.0    #(256, 256, 3)\n",
    "  return x, y\n",
    "\n",
    "def read_mask_predict(path):\n",
    "  x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "  x = cv2.resize(x, (256,256))\n",
    "  x = np.expand_dims(x, axis = -1)    #(256, 256, 1)\n",
    "  return x\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfac7de-ba1d-4e1c-a837-82766ef6d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f0695-374a-4379-9650-0e98c9b55a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6b4bc-ab50-4817-a2ce-937b55f56dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        return np.float32(x)\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a77d8f-fedc-4699-ac39-ced98902137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    denominator = K.sum(y_true_f) + K.sum(y_pred_f)\n",
    "\n",
    "    dice_score = (2. * intersection + smooth) / (denominator + smooth)\n",
    "    log_dice = -K.log(dice_score)\n",
    "\n",
    "    return log_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74523b6a-c163-401c-9c00-d9daa9317b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dice_bce_loss(y_true, y_pred, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Combined Log Dice + Binary Cross Entropy Loss.\n",
    "    \"\"\"\n",
    "    ce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice = log_dice_loss(y_true, y_pred)\n",
    "    return alpha * dice + (1 - alpha) * ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5b038-5eca-411e-b63f-e79739d9c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, sample_data, save_dir):\n",
    "        super().__init__()\n",
    "        self.sample_data = sample_data  # Tuple (input_image, true_mask)\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        input_image, true_mask = self.sample_data\n",
    "        prediction = self.model.predict(tf.expand_dims(input_image, axis=0))[0]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(input_image, cmap='gray')\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_mask, cmap='gray')\n",
    "        plt.title('True Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(prediction, cmap='gray')\n",
    "        plt.title(f'Prediction at Epoch {epoch + 1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.save_dir, f'epoch_{epoch + 1}.png'))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd68cfd-5cfa-4260-98f2-2d612ac5f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "fold_accuracies, fold_losses, fold_ious = [], [], []\n",
    "\n",
    "model_save_file = \"XBoundNetCombinedLDL07BCE03Drop02onlowresLre4.h5\"\n",
    "#model_save_file = \"XBoundNetLDLDrop02Lre3.h5\"\n",
    "#model_save_file = \"XBoundNetLDLDrop02.h5\"\n",
    "#model_save_file = \"XBoundNetLDLNoDrop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc29d62-3963-481e-8055-9fcf2b295c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = 4\n",
    "epochs = 400\n",
    "lr = 1e-4\n",
    "#lr = 1e-3\n",
    "\n",
    "\n",
    "for fold, (trainval_idx, test_idx) in enumerate(kf.split(images)):\n",
    "    print(f\"\\n🔹 Training Fold {fold + 1}/5\")\n",
    "    \n",
    "    trainval_x, test_x = images[trainval_idx], images[test_idx]\n",
    "    trainval_y, test_y = masks[trainval_idx], masks[test_idx]\n",
    "\n",
    "    # From trainval (80% of total), carve out 16% as validation\n",
    "    train_x, val_x, train_y, val_y = train_test_split(\n",
    "        trainval_x, trainval_y, test_size=0.16, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Confirm split sizes\n",
    "    print(f\"  Train: {len(train_x)} | Val: {len(val_x)} | Test: {len(test_x)}\")\n",
    "    \n",
    "    # Prepare TF datasets\n",
    "    # Augmentation is applied dynamically each epoch\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch, augment=True)\n",
    "    valid_dataset = tf_dataset(val_x, val_y, batch=batch)\n",
    "\n",
    "    #model = ResUnetPlusPlus()\n",
    "    model = XBoundNetPP()\n",
    "\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "    metrics = [\"acc\", Recall(), Precision(), iou]\n",
    "    #model.compile(loss=log_dice_loss, optimizer=opt, metrics=metrics)\n",
    "    model.compile(loss=log_dice_bce_loss, optimizer=opt, metrics=metrics)\n",
    "    \n",
    "    # Define original network path (TensorFlow has issues with $)\n",
    "    network_log_path = r\"/path/to/dataset/XBoundNet/tensorflow_logs\"\n",
    "    \n",
    "    network_log_dir = os.path.join(network_log_path, model_save_file)\n",
    "    os.makedirs(network_log_dir, exist_ok=True)\n",
    "    \n",
    "    # Define a TEMPORARY local log directory\n",
    "    local_log_dir = os.path.expanduser(\"~/tensorflow_logs\")  # Works for both Windows & Linux\n",
    "    \n",
    "    # Ensure the local directory exists\n",
    "    os.makedirs(local_log_dir, exist_ok=True)\n",
    "    \n",
    "    # Debugging\n",
    "    print(f\"✅ Local log directory being used: {local_log_dir}\")\n",
    "\n",
    "    # Load and preprocess the sample image and mask\n",
    "    sample_image_valid, t = read_image_predict(val_x[0])  # This should return a preprocessed image tensor\n",
    "    sample_mask_valid = read_mask_predict(val_y[0])    # This should return a preprocessed mask tensor\n",
    "    \n",
    "    # Ensure the data types match the model's expectations\n",
    "    sample_image_valid = tf.convert_to_tensor(sample_image_valid, dtype=tf.float32)\n",
    "    sample_mask_valid = tf.convert_to_tensor(sample_mask_valid, dtype=tf.float32)\n",
    "    \n",
    "    # Create the sample data tuple\n",
    "    sample_data_valid = (sample_image_valid, sample_mask_valid)\n",
    "    \n",
    "    save_dir_valid = 'prediction_monitoring_validation'\n",
    "    prediction_monitor_validation = PredictionMonitor(sample_data_valid, save_dir_valid)\n",
    "    \n",
    "    # Load and preprocess the sample image and mask\n",
    "    sample_image_training, t = read_image_predict(train_x[0])  # This should return a preprocessed image tensor\n",
    "    sample_mask_training = read_mask_predict(train_y[0])    # This should return a preprocessed mask tensor\n",
    "    \n",
    "    # Ensure the data types match the model's expectations\n",
    "    sample_image_training = tf.convert_to_tensor(sample_image_training, dtype=tf.float32)\n",
    "    sample_mask_training = tf.convert_to_tensor(sample_mask_training, dtype=tf.float32)\n",
    "    \n",
    "    # Create the sample data tuple\n",
    "    sample_data_training = (sample_image_training, sample_mask_training)\n",
    "    \n",
    "    save_dir_train = 'prediction_monitoring_training'\n",
    "    prediction_monitor_training = PredictionMonitor(sample_data_training, save_dir_train)\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(f\"XBoundNet_{fold + 1}Fold_LDL07_BCE03_Drop02onlowres_Lre4.h5\", save_best_only=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=15),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=local_log_dir, histogram_freq=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True),\n",
    "        prediction_monitor_training, prediction_monitor_validation\n",
    "    ]\n",
    "\n",
    "    train_steps = len(train_x) // batch\n",
    "    valid_steps = len(val_x) // batch\n",
    "    train_steps += 1 if len(train_x) % batch != 0 else 0\n",
    "    valid_steps += 1 if len(val_x) % batch != 0 else 0\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=epochs,\n",
    "        #steps_per_epoch=train_steps,\n",
    "        validation_steps=valid_steps,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False#, verbose=2\n",
    "    )\n",
    "\n",
    "    # ✅ Evaluate Model\n",
    "    loss, acc, rec, prec, iou_score = model.evaluate(valid_dataset, steps=valid_steps)\n",
    "    print(f\"🔹 Fold {fold + 1} → Loss: {loss:.4f}, Accuracy: {acc:.4f}, IoU: {iou_score:.4f}\")\n",
    "\n",
    "    # ✅ Store results\n",
    "    fold_losses.append(loss)\n",
    "    fold_accuracies.append(acc)\n",
    "    fold_ious.append(iou_score)\n",
    "\n",
    "# ✅ Final Results\n",
    "print(\"\\n✅ Final 5-Fold Cross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "print(f\"Average Loss: {np.mean(fold_losses):.4f} ± {np.std(fold_losses):.4f}\")\n",
    "print(f\"Average IoU: {np.mean(fold_ious):.4f} ± {np.std(fold_ious):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e002b1-725e-4b1b-bced-66c7f92767f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_logs():\n",
    "    try:\n",
    "        if os.path.exists(network_log_dir):\n",
    "            print(f\"✅ Moving logs from {local_log_dir} → {network_log_dir}\")\n",
    "            shutil.copytree(local_log_dir, network_log_dir, dirs_exist_ok=True)\n",
    "            print(\"✅ Logs moved successfully.\")\n",
    "        else:\n",
    "            print(f\"⚠️ Network path {network_log_dir} not found. Copy manually.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error moving logs: {e}\")\n",
    "\n",
    "move_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd348fb-17d4-4b79-a1f6-d60db3f90534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = 4\n",
    "epochs = 400\n",
    "lr = 1e-4\n",
    "#lr = 1e-3\n",
    "\n",
    "for i in range(1, 6):\n",
    "    set_seed(1000+i)\n",
    "    \n",
    "    for fold, (trainval_idx, test_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\n🔹 Training Fold {fold + 1}/5\")\n",
    "        \n",
    "        trainval_x, test_x = images[trainval_idx], images[test_idx]\n",
    "        trainval_y, test_y = masks[trainval_idx], masks[test_idx]\n",
    "    \n",
    "        # From trainval (80% of total), carve out 16% as validation\n",
    "        train_x, val_x, train_y, val_y = train_test_split(\n",
    "            trainval_x, trainval_y, test_size=0.16, random_state=42+i\n",
    "        )\n",
    "        \n",
    "        # Confirm split sizes\n",
    "        print(f\"  Train: {len(train_x)} | Val: {len(val_x)} | Test: {len(test_x)}\")\n",
    "        \n",
    "        # Prepare TF datasets\n",
    "        # Augmentation is applied dynamically each epoch\n",
    "        train_dataset = tf_dataset(train_x, train_y, batch=batch, augment=True)\n",
    "        valid_dataset = tf_dataset(val_x, val_y, batch=batch)\n",
    "    \n",
    "        #model = ResUnetPlusPlus()\n",
    "        model = XBoundNetPP()\n",
    "    \n",
    "    \n",
    "        opt = tf.keras.optimizers.Adam(lr)\n",
    "        metrics = [\"acc\", Recall(), Precision(), iou]\n",
    "        #model.compile(loss=log_dice_loss, optimizer=opt, metrics=metrics)\n",
    "        model.compile(loss=log_dice_bce_loss, optimizer=opt, metrics=metrics)\n",
    "        \n",
    "    \n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(f\"XBoundNet_{fold + 1}Fold_LDL07_BCE03_Drop02onlowres_Lre4_ensemble_model_{i}.h5\", save_best_only=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=15),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True),\n",
    "        ]\n",
    "    \n",
    "        train_steps = len(train_x) // batch\n",
    "        valid_steps = len(val_x) // batch\n",
    "        train_steps += 1 if len(train_x) % batch != 0 else 0\n",
    "        valid_steps += 1 if len(val_x) % batch != 0 else 0\n",
    "    \n",
    "    \n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=valid_dataset,\n",
    "            epochs=epochs,\n",
    "            #steps_per_epoch=train_steps,\n",
    "            validation_steps=valid_steps,\n",
    "            callbacks=callbacks,\n",
    "            shuffle=False#, verbose=2\n",
    "        )\n",
    "    \n",
    "        # ✅ Evaluate Model\n",
    "        loss, acc, rec, prec, iou_score = model.evaluate(valid_dataset, steps=valid_steps)\n",
    "        print(f\"🔹 Fold {fold + 1} → Loss: {loss:.4f}, Accuracy: {acc:.4f}, IoU: {iou_score:.4f}\")\n",
    "    \n",
    "        # ✅ Store results\n",
    "        fold_losses.append(loss)\n",
    "        fold_accuracies.append(acc)\n",
    "        fold_ious.append(iou_score)\n",
    "    \n",
    "    # ✅ Final Results\n",
    "    print(\"\\n✅ Final Ensemble 5-Fold Cross-Validation Results:\")\n",
    "    print(f\"Average Ensemble Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
    "    print(f\"Average Ensemble Loss: {np.mean(fold_losses):.4f} ± {np.std(fold_losses):.4f}\")\n",
    "    print(f\"Average Ensemble IoU: {np.mean(fold_ious):.4f} ± {np.std(fold_ious):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee63d36-5099-4927-9726-528822fe713a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_image_predict(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    y = cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n",
    "    y = cv2.resize(y, (256,256))\n",
    "    y = y/255.0\n",
    "    x = cv2.resize(x, (256,256))\n",
    "    x = x/255.0    #(256, 256, 3)\n",
    "    return x, y\n",
    "\n",
    "def read_mask_predict(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (256,256))\n",
    "    x = np.expand_dims(x, axis = -1)    #(256, 256, 1)\n",
    "    return x\n",
    "\n",
    "def normalize_img(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n",
    "    x = cv2.resize(x, (256,256))\n",
    "    normalized_img = cv2.normalize(x, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = [mask, mask, mask]\n",
    "    mask = np.transpose(mask, (1, 2, 0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b81d0-c616-406e-8808-54d941b96382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_largest_component(mask):    \n",
    "    # Find all connected components\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "\n",
    "    if num_labels <= 1:\n",
    "        return binary_mask  # Only background or no components found\n",
    "\n",
    "    # Ignore label 0 (background), get label of largest component\n",
    "    largest_component = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "\n",
    "    # Create new mask with only the largest component\n",
    "    cleaned_mask = (labels == largest_component).astype(np.uint8) * 255\n",
    "    return np.expand_dims(cleaned_mask, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d04b9-dae1-427a-8159-434544955c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_dual_mask_boundary(original_image, gt_mask, pred_mask):\n",
    "    \"\"\"\n",
    "    Overlays both the ground truth and predicted mask boundaries on the original image.\n",
    "    \n",
    "    Args:\n",
    "        original_image (numpy array): Original RGB image.\n",
    "        gt_mask (numpy array): Ground truth binary segmentation mask.\n",
    "        pred_mask (numpy array): Predicted binary segmentation mask.\n",
    "    \n",
    "    Returns:\n",
    "        overlayed_image (numpy array): Original image with both boundaries overlayed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure masks are grayscale\n",
    "    if len(gt_mask.shape) == 3:\n",
    "        gt_mask = cv2.cvtColor(gt_mask, cv2.COLOR_RGB2GRAY)\n",
    "    if len(pred_mask.shape) == 3:\n",
    "        pred_mask = cv2.cvtColor(pred_mask, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Convert masks to binary (0 or 255)\n",
    "    gt_mask = (gt_mask > 0.5).astype(np.uint8) * 255\n",
    "    pred_mask = (pred_mask > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Find contours in both masks\n",
    "    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    pred_contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a copy of the original image\n",
    "    overlayed_image = original_image.copy()\n",
    "\n",
    "    # Draw ground truth contours in **Red**\n",
    "    cv2.drawContours(overlayed_image, gt_contours, -1, (255, 0, 0), 1)  # Red boundary\n",
    "\n",
    "    # Draw predicted contours in **Green**\n",
    "    cv2.drawContours(overlayed_image, pred_contours, -1, (0, 255, 0), 1)  # Green boundary\n",
    "\n",
    "    return overlayed_image\n",
    "\n",
    "def generate_heatmap(model, image, layer = \"conv2d_37\"):\n",
    "    \"\"\"\n",
    "    Generates a heatmap from the last convolutional layer.\n",
    "    \"\"\"\n",
    "    # Select the last convolutional layer in your model\n",
    "    last_conv_layer = model.get_layer(layer)  # Update layer name if needed\n",
    "    heatmap_model = tf.keras.models.Model(inputs=model.input, outputs=last_conv_layer.output)\n",
    "\n",
    "    # Expand dimensions to match the model's expected input shape\n",
    "    img_array = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Get activations\n",
    "    conv_output = heatmap_model.predict(img_array)\n",
    "\n",
    "    # Compute the mean activation across all filters\n",
    "    heatmap = np.mean(conv_output, axis=-1)[0]\n",
    "\n",
    "    # Normalize the heatmap for visualization\n",
    "    heatmap = cv2.resize(heatmap, (256, 256))\n",
    "    heatmap = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "\n",
    "    # Apply colormap (Jet colormap makes high-confidence areas red/yellow)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d3862-aaa0-4af8-b0e8-3476a12aca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\" Enable dropout at inference time. \"\"\"\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Dropout):\n",
    "            layer.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5666a46-bd54-42c9-b875-ad3b80b6614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_predictions(model, image, n_samples=50):\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        pred = model(np.expand_dims(image, axis=0), training=True)[0]  # Force dropout active\n",
    "        predictions.append(pred.numpy())\n",
    "\n",
    "    predictions = np.stack(predictions, axis=0)\n",
    "    mean_prediction = np.mean(predictions, axis=0)\n",
    "    std_prediction = np.std(predictions, axis=0)\n",
    "\n",
    "    return mean_prediction, std_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67861f6-5945-4e6c-8c71-46c05893b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu(uncertainty_map):\n",
    "    \"\"\"Mean Uncertainty (MU) as the average standard deviation across the map.\"\"\"\n",
    "    return np.mean(uncertainty_map)\n",
    "\n",
    "def calculate_ruv(uncertainty_map, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Region Uncertainty Volume (RUV) as the proportion of pixels above a threshold.\n",
    "    \"\"\"\n",
    "    uncertain_area = np.sum(uncertainty_map > threshold)\n",
    "    total_area = uncertainty_map.size\n",
    "    return uncertain_area / total_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b749a8-80d9-48a3-90c5-3e8b006d6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uncertainty_metrics(mc_predictions):\n",
    "    eps = 1e-8\n",
    "    mc_predictions = np.squeeze(mc_predictions, axis=-1)  # (N, H, W)\n",
    "\n",
    "    # Mean prediction (mean probability)\n",
    "    mean_pred = np.mean(mc_predictions, axis=0)\n",
    "\n",
    "    # Predictive Entropy H(mean)\n",
    "    predictive_entropy = -(\n",
    "        mean_pred * np.log(mean_pred + eps) +\n",
    "        (1 - mean_pred) * np.log(1 - mean_pred + eps)\n",
    "    )\n",
    "\n",
    "    # Expected Entropy E[H(p)]\n",
    "    expected_entropy = np.mean(\n",
    "        -(\n",
    "            mc_predictions * np.log(mc_predictions + eps) +\n",
    "            (1 - mc_predictions) * np.log(1 - mc_predictions + eps)\n",
    "        ),\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    # Mutual Information = H(mean) - E[H(p)]\n",
    "    mutual_information = predictive_entropy - expected_entropy\n",
    "\n",
    "    # Variance\n",
    "    variance = np.var(mc_predictions, axis=0)\n",
    "\n",
    "    return predictive_entropy, expected_entropy, mutual_information, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818cea9-6020-4639-8535-d50731ce7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_file = \"Ensemble_XBoundNetCombinedLDL07BCE03Drop02onlowresLre4.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0044b-f177-48be-9a70-fd3e940d20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(\"kaz_segmentation_results\", model_save_file.rsplit('.', 1)[0])\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdb800-3ce1-4f32-98eb-e3e6fa90e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_file = \"XBoundNetCombinedLDL07BCE03Drop02onlowresLre4.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce787f7-84e5-4ab1-9c65-76dad0729d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models\n",
    "models = [\n",
    "    tf.keras.models.load_model(f\"XBoundNet_{i}Fold_LDL07_BCE03_Drop02onlowres_Lre4.h5\", custom_objects={\"iou\": iou, \"log_dice_bce_loss\": log_dice_bce_loss})\n",
    "    for i in range(1, 6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516a131-04e0-44a0-a2d2-8b2f20e7b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_largest_components(prediction, threshold=0.4, min_component_area=50, apply_morph=True, component_rank=1):\n",
    "    \n",
    "    # Step 1: Threshold the soft prediction\n",
    "    binary_mask = (prediction > threshold).astype(np.uint8)\n",
    "\n",
    "    # Optional: Morphological closing to seal small holes/gaps\n",
    "    if apply_morph:\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Step 2: Connected components\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)\n",
    "\n",
    "    # Step 3: Keep largest valid component (ignore background label 0)\n",
    "    if num_labels <= 1:\n",
    "        return np.zeros_like(prediction, dtype=np.uint8)[..., np.newaxis]\n",
    "\n",
    "    # Step 3: Sort components by area, descending (excluding background 0)\n",
    "    component_areas = [\n",
    "        (i, stats[i, cv2.CC_STAT_AREA]) for i in range(1, num_labels)\n",
    "        if stats[i, cv2.CC_STAT_AREA] > min_component_area\n",
    "    ]\n",
    "    sorted_components = sorted(component_areas, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if len(sorted_components) < component_rank:\n",
    "        return np.zeros_like(prediction, dtype=np.uint8)[..., np.newaxis]\n",
    "\n",
    "    target_component = sorted_components[component_rank - 1][0]\n",
    "    cleaned_mask = (labels == target_component).astype(np.uint8)\n",
    "    filled_mask = binary_fill_holes(cleaned_mask).astype(np.uint8) * 255\n",
    "    return filled_mask[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f28a1-77c9-42f7-86ff-30ce508d7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_uncertainty_mask(image, prediction, ground_truth, uncertainty_map, thresholds=[0, 25, 50, 75], alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay uncertainty-aware TP/FP/FN/Uncertain masks using thresholds in [0,100] (not percentile).\n",
    "    \"\"\"\n",
    "    assert image.shape[:2] == prediction.shape == ground_truth.shape == uncertainty_map.shape\n",
    "    results = []\n",
    "    norm_unc_map = (uncertainty_map / np.max(uncertainty_map)) * 100.0\n",
    "\n",
    "    for t in thresholds:\n",
    "        # Mask for certain voxels\n",
    "        certain_mask = (norm_unc_map <= t).astype(np.uint8)\n",
    "\n",
    "        pred_masked = prediction * certain_mask\n",
    "        gt_masked = ground_truth * certain_mask\n",
    "\n",
    "        # Categories\n",
    "        tp = np.logical_and(pred_masked == 1, gt_masked == 1)\n",
    "        fp = np.logical_and(pred_masked == 1, gt_masked == 0)\n",
    "        fn = np.logical_and(pred_masked == 0, gt_masked == 1)\n",
    "        uncertain = (certain_mask == 0)\n",
    "\n",
    "        # Base image\n",
    "        base = (image * 255).astype(np.uint8) if image.max() <= 1.0 else image.copy()\n",
    "        if base.ndim == 2:\n",
    "            base = cv2.cvtColor(base, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        overlay = base.astype(np.float32)\n",
    "\n",
    "        overlay[tp] = (1 - alpha) * overlay[tp] + alpha * np.array([0, 255, 0])     # Green\n",
    "        overlay[fp] = (1 - alpha) * overlay[fp] + alpha * np.array([0, 0, 255])     # Red\n",
    "        overlay[fn] = (1 - alpha) * overlay[fn] + alpha * np.array([255, 0, 0])     # Blue\n",
    "        overlay[uncertain] = (1 - alpha) * overlay[uncertain] + alpha * np.array([255, 255, 0])  # Yellow\n",
    "\n",
    "        overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "        results.append((t, overlay))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db4006-b954-48aa-82fa-cec40122636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_mask_overlay(mask, original_img, color=(200, 200, 255), alpha = 0.25):\n",
    "    base = original_img.copy().astype(np.float32)\n",
    "    overlay = base.copy().astype(np.float32)\n",
    "    mask_color = np.zeros_like(base)\n",
    "    mask_color[mask > 0] = color\n",
    "    overlay = cv2.addWeighted(overlay, 1 - alpha, mask_color.astype(np.float32), alpha, 0)\n",
    "    return overlay\n",
    "\n",
    "def heatmap_overlay(conf_map, original_img, alpha = 0.25):\n",
    "    base = original_img.copy().astype(np.float32)\n",
    "    colormap = cv2.applyColorMap(conf_map, cv2.COLORMAP_INFERNO)\n",
    "    overlay = cv2.addWeighted(base, 1 - alpha, colormap.astype(np.float32), alpha, 0)\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbf0ca-1790-4f57-928a-3cfd735f600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_images(show_final=True, show_conv_layers=False, show_thresholds=False, show_uncertainty=False):\n",
    "    # Iterate through test images\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\n🔹 Predicting on Fold {fold + 1}/5\")\n",
    "    \n",
    "        test_x_fold, test_y_fold = images[test_idx], masks[test_idx]  # Get test images/masks for the current fold\n",
    "    \n",
    "        model = models[fold]  # Load corresponding trained model\n",
    "    \n",
    "        for x_path, y_path in tqdm(zip(test_x_fold, test_y_fold), total=len(test_x_fold)):\n",
    "            fname = os.path.basename(x_path)\n",
    "            tname = fname.rsplit('.', 1)[0]\n",
    "            #if (tname != \"Pt 0006 - RA - TestID20240221154926--02-2810-21-39\"):\n",
    "             #   continue\n",
    "            output_path = os.path.join(output_dir, tname)\n",
    "            print(\"saving to: \" + output_path)\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            #tname = \"test_\" + tname\n",
    "            x, rgb_img = read_image_predict(x_path)\n",
    "            y = read_mask_predict(y_path)\n",
    "            x_normalized = normalize_img(x_path)\n",
    "        \n",
    "            # Generate predictions\n",
    "            mc_predictions = np.stack([\n",
    "                model(np.expand_dims(x, axis=0), training=True)[0].numpy()\n",
    "                for _ in range(50)\n",
    "            ], axis=0)  # (50, 256, 256, 1)\n",
    "            \n",
    "            mean_pred, uncertainty_map = monte_carlo_predictions(model, x, n_samples=50)\n",
    "            mean_pred_calibrated = calibrate_predictions(mean_pred, calibrator)\n",
    "            p_entropy, e_entropy, mi, var = compute_uncertainty_metrics(mc_predictions)\n",
    "\n",
    "            calibrated_pred = cv2.normalize(mean_pred_calibrated, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            calibrated_pred = calibrated_pred.astype(np.uint8)\n",
    "      \n",
    "            processed_pred_resized = keep_largest_components(calibrated_pred, threshold=70)\n",
    "\n",
    "            binary_gt = (y > 127).astype(np.uint8).squeeze()\n",
    "            binary_pred = (processed_pred_resized > 127).astype(np.uint8).squeeze()\n",
    "            \n",
    "            overlays = overlay_uncertainty_mask(rgb_img, binary_pred, binary_gt, p_entropy, thresholds=[100, 75, 50, 25])\n",
    "            \n",
    "            for th, vis in overlays:\n",
    "                tmp_path = os.path.join(output_path, f\"Threshold_{th}.bmp\")\n",
    "                cv2.imwrite(tmp_path, vis)\n",
    "                if show_thresholds:\n",
    "                    plt.figure(figsize=(5, 5))\n",
    "                    plt.imshow(vis)\n",
    "                    plt.title(f\"Threshold {th}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.show()\n",
    "\n",
    "        \n",
    "            conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "            for i, layer in enumerate(conv_layers):\n",
    "                #print(f\"Layer {i}: {layer.name}, Output Shape: {layer.output_shape}\")\n",
    "                heatmap = generate_heatmap(model, x, layer.name)\n",
    "    \n",
    "                if show_conv_layers:\n",
    "                    # Display heatmap for the current layer\n",
    "                    plt.figure(figsize=(6, 6))\n",
    "                    plt.imshow(heatmap)\n",
    "                    plt.axis('off')\n",
    "                    plt.title(f\"Heatmap from Layer: {layer.name}\")\n",
    "                    \n",
    "                    # Show each heatmap separately\n",
    "                    plt.show()\n",
    "        \n",
    "                # Convert heatmap to uint8 (0-255) for saving\n",
    "                #heatmap_uint8 = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    \n",
    "                overlay_result = overlay_dual_mask_boundary(heatmap, mask_parse(y), mask_parse(binary_pred))\n",
    "                tmp_path = os.path.join(output_path, f\"{layer.name}_with_contour.bmp\")\n",
    "                cv2.imwrite(tmp_path, overlay_result)     \n",
    "                tmp_path = os.path.join(output_path, f\"{layer.name}.bmp\")\n",
    "                cv2.imwrite(tmp_path, heatmap)\n",
    "                    \n",
    "    \n",
    "            tmp_path = os.path.join(output_path, \"original_image.bmp\")\n",
    "            og_uint8 = cv2.normalize(rgb_img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            cv2.imwrite(tmp_path, og_uint8) \n",
    "        \n",
    "            tmp_path = os.path.join(output_path, \"groundtruth_mask.bmp\")\n",
    "            cv2.imwrite(tmp_path, y)\n",
    "        \n",
    "            tmp_path = os.path.join(output_path, \"predicted_mask.bmp\")\n",
    "            cv2.imwrite(tmp_path, processed_pred_resized)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"mean_prediction_map.bmp\")\n",
    "            pred_map_uint8 = cv2.normalize(mean_pred.squeeze(), None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_pred = cv2.applyColorMap(pred_map_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_pred)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"uncertainty_map.bmp\")\n",
    "            uncert_map_uint8 = cv2.normalize(uncertainty_map, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_uncert = cv2.applyColorMap(uncert_map_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_uncert)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"Mutual_Information_(Epistemic).bmp\")\n",
    "            mi_uint8 = cv2.normalize(mi, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_mi = cv2.applyColorMap(mi_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_mi)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"Predictive_Entropy.bmp\")\n",
    "            p_entropy_uint8 = cv2.normalize(p_entropy, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_pe = cv2.applyColorMap(p_entropy_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_pe)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"Variance.bmp\")\n",
    "            var_uint8 = cv2.normalize(var, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_var = cv2.applyColorMap(var_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_var)\n",
    "            \n",
    "            contour_result_on_original = overlay_dual_mask_boundary(x_normalized, mask_parse(y), mask_parse(binary_pred))\n",
    "            tmp_path = os.path.join(output_path, \"contour_result_on_original.bmp\")\n",
    "            cont_uint8 = cv2.normalize(contour_result_on_original, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            cv2.imwrite(tmp_path, cont_uint8)\n",
    "\n",
    "            prediction_over_img = binary_mask_overlay(processed_pred_resized.squeeze(), x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"prediction_over_img.bmp\")\n",
    "            cv2.imwrite(tmp_path, prediction_over_img)\n",
    "\n",
    "            mask_over_img = binary_mask_overlay(y.squeeze(), x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"mask_over_img.bmp\")\n",
    "            cv2.imwrite(tmp_path, mask_over_img)\n",
    "\n",
    "            heatmap_over_image = heatmap_overlay(pred_map_uint8, x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"heatmap_over_image.bmp\")\n",
    "            cv2.imwrite(tmp_path, heatmap_over_image)\n",
    "\n",
    "            uncertainty_over_image = heatmap_overlay(uncert_map_uint8, x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"uncertainty_over_image.bmp\")\n",
    "            cv2.imwrite(tmp_path, uncertainty_over_image)\n",
    "                        \n",
    "            if show_uncertainty:\n",
    "                # 🔍 Show predictions\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(processed_pred_resized.squeeze(), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Processed Prediction\")\n",
    "                plt.show()\n",
    "                \n",
    "                # Display heatmap for the current layer\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(mean_pred)\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Mean prediction map\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                #plt.imshow(uncertainty_map)\n",
    "                plt.imshow(uncertainty_map, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"uncertainty prediction map\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(mi, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Mutual Information (Epistemic)\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(p_entropy, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Predictive Entropy\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(var, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Variance (Std Dev²)\")\n",
    "                plt.show()\n",
    "            \n",
    "            if show_final:\n",
    "\n",
    "                # Normalize grayscale base\n",
    "                base_gray = x_normalized.astype(np.float32)\n",
    "                base_gray -= base_gray.min()\n",
    "                base_gray /= (base_gray.max() + 1e-8)\n",
    "            \n",
    "                fig, axes = plt.subplots(1, 5, figsize=(32, 5))\n",
    "            \n",
    "                # 1. Original Image\n",
    "                axes[0].imshow(base_gray, cmap='gray')  # Ensure grayscale colormap is used\n",
    "                axes[0].set_title(f\"Original Image: {tname}\")\n",
    "                axes[0].axis(\"off\")\n",
    "            \n",
    "                # 2. Ground Truth Mask\n",
    "                axes[1].imshow(base_gray, cmap='gray')\n",
    "                gt_mask = np.ma.masked_where(binary_gt == 0, binary_gt)\n",
    "                axes[1].imshow(gt_mask, cmap='spring', alpha=0.25)\n",
    "                axes[1].set_title(\"Annotated Mask over Image\")\n",
    "                axes[1].axis(\"off\")\n",
    "            \n",
    "                # 3. Predicted Mask\n",
    "                axes[2].imshow(base_gray, cmap='gray')\n",
    "                pred_mask = np.ma.masked_where(binary_pred == 0, binary_pred)\n",
    "                axes[2].imshow(pred_mask, cmap='winter', alpha=0.25)\n",
    "                axes[2].set_title(\"Predicted Mask over Image\")\n",
    "                axes[2].axis(\"off\")\n",
    "                            \n",
    "                # 4. Probability Map Overlay\n",
    "                axes[3].imshow(base_gray, cmap='gray')\n",
    "                mean_mask = np.ma.masked_where(mean_pred <= 0.001, mean_pred)\n",
    "                im3 = axes[3].imshow(mean_mask, cmap='magma', alpha=0.25)\n",
    "                axes[3].set_title(\"Probability over Image\")\n",
    "                axes[3].axis(\"off\")\n",
    "                cbar = fig.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "                cbar.set_label(\"Probability\", rotation=270, labelpad=15)\n",
    "            \n",
    "                # 5. Uncertainty Map Overlay\n",
    "                axes[4].imshow(base_gray, cmap='gray')\n",
    "                uncert_mask = np.ma.masked_where(uncertainty_map <= 0.03, uncertainty_map)\n",
    "                im4 = axes[4].imshow(uncert_mask, cmap='magma', alpha=0.25)\n",
    "                axes[4].set_title(\"Uncertainty over Image\")\n",
    "                axes[4].axis(\"off\")\n",
    "                cbar = fig.colorbar(im4, ax=axes[4], fraction=0.046, pad=0.04)\n",
    "                cbar.set_label(\"Uncertainty\", rotation=270, labelpad=15)\n",
    "            \n",
    "                # Save\n",
    "                tmp_path = os.path.join(output_path, \"output_side_to_side.png\")\n",
    "                plt.savefig(tmp_path, bbox_inches=\"tight\", dpi=600)\n",
    "                plt.tight_layout()\n",
    "                #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cab572-e7b8-4f2b-a236-33c24d7169d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images(show_thresholds = True, show_uncertainty = True, show_final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d122c83-0614-4877-acbc-46b7ca53689e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images(show_final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bb05a-348b-4269-a859-55e0a399d0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_val_preds = []\n",
    "all_val_labels = []\n",
    "\n",
    "for fold, (trainval_idx, test_idx) in enumerate(kf.split(images)):\n",
    "    print(f\"\\n🔹 Training Fold {fold + 1}/5\")\n",
    "    \n",
    "    trainval_x_fold, test_x_fold = images[trainval_idx], images[test_idx]\n",
    "    trainval_y_fold, test_y_fold = masks[trainval_idx], masks[test_idx]\n",
    "\n",
    "    # From trainval (80% of total), carve out 16% as validation\n",
    "    train_x_fold, val_x_fold, train_y_fold, val_y_fold = train_test_split(\n",
    "        trainval_x_fold, trainval_y_fold, test_size=0.16, random_state=42\n",
    "    )\n",
    "\n",
    "    model = models[fold]  # Load corresponding trained model\n",
    "\n",
    "    for xval, yval in tqdm(zip(val_x_fold, val_y_fold), total=len(val_x_fold)):\n",
    "        x, rgb_img = read_image_predict(xval)\n",
    "        y = read_mask_predict(yval)\n",
    "        y_bin = (y > 127).astype(np.uint8)  # ✅ Convert to 0/1\n",
    "        \n",
    "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
    "        \n",
    "        all_val_preds.append(y_pred.flatten())\n",
    "        all_val_labels.append(y_bin.flatten())\n",
    "        \n",
    "val_preds = np.concatenate(all_val_preds)\n",
    "val_labels = np.concatenate(all_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce77b97-775e-404e-800b-36f0d02f346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = LogisticRegression(solver='liblinear')\n",
    "calibrator.fit(val_preds.reshape(-1, 1), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36b4ca-450d-43c9-ae4c-e8642753c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibratorname = f\"sigmoid_calibrator{model_save_file.rsplit('.', 1)[0]}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34392a-4bc6-4640-8ef0-8b6e138356ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(calibrator, calibratorname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7923859-69f0-4cd1-b86b-d46d2bd2f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = joblib.load(calibratorname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fc400-4fb5-4909-a0f1-cf2eba034668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_predictions(raw_preds, calibrator):\n",
    "    flat_preds = raw_preds.flatten()\n",
    "    calibrated_flat = calibrator.predict_proba(flat_preds.reshape(-1, 1))[:, 1]\n",
    "    return calibrated_flat.reshape(raw_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f91e71-e563-4b4a-82b1-26bf70ebdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"acc\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78eb7e2-aa7b-40ff-b9cb-6218338e6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_dataset, steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7252d-d574-48f0-a42c-86367e44ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output_path = r\"/path/to/dataset/Predictions\"\n",
    "#pred_folder_name = \"XBN_AUG_LDL_NODROP\"\n",
    "#pred_folder_name = \"XBN_AUG_LDL_DROP02\"\n",
    "#pred_folder_name = \"XBN_AUG_LDL_DROP02Lre3\"\n",
    "#pred_folder_name = \"XBN_AUG_LDL07_BCE03_DROP02onlylowres_Lre4\"\n",
    "pred_folder_name = \"Ensemble_XBN_AUG_LDL07_BCE03_DROP02onlylowres_Lre4\"\n",
    "pred_output_dir = os.path.join(pred_output_path, pred_folder_name)\n",
    "os.makedirs(pred_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118fd75-2c43-42cc-b12a-14da2d406b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store evaluation results\n",
    "test_fold_losses, test_fold_accuracies, test_fold_recall, test_fold_precision, test_fold_ious = [], [], [], [], []\n",
    "\n",
    "valid_fold_losses, valid_fold_accuracies, valid_fold_recall, valid_fold_precision, valid_fold_ious = [], [], [], [], []\n",
    "\n",
    "# ✅ Evaluate each model on its corresponding validation set\n",
    "for fold, (trainval_idx, test_idx) in enumerate(kf.split(images)):\n",
    "\n",
    "    trainval_x, test_x = images[trainval_idx], images[test_idx]\n",
    "    trainval_y, test_y = masks[trainval_idx], masks[test_idx]\n",
    "\n",
    "    # From trainval (80% of total), carve out 16% as validation\n",
    "    train_x, val_x, train_y, val_y = train_test_split(\n",
    "        trainval_x, trainval_y, test_size=0.16, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Prepare TF datasets\n",
    "    test_dataset = tf_dataset(test_x, test_y, batch=8)\n",
    "    valid_dataset = tf_dataset(val_x, val_y, batch=8)\n",
    "    \n",
    "\n",
    "    # Evaluate the corresponding model\n",
    "    model_f = models[fold]\n",
    "    testloss, testacc, testrec, testprec, testiou_score = model_f.evaluate(test_dataset, steps=len(test_x) // 4)\n",
    "    validloss, validacc, validrec, validprec, validiou_score = model_f.evaluate(valid_dataset, steps=len(val_x) // 4)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"🔹 Fold {fold + 1} on Test Set → Loss: {testloss:.3f}, Accuracy: {testacc:.3f}, Recall: {testrec:.3f}, Precision: {testprec:.3f}, IoU: {testiou_score:.3f}\")\n",
    "    print(f\"🔹 Fold {fold + 1} on Validation Set → Loss: {validloss:.3f}, Accuracy: {validacc:.3f}, Recall: {validrec:.3f}, Precision: {validprec:.3f}, IoU: {validiou_score:.3f}\")\n",
    "\n",
    "    # Store results\n",
    "    test_fold_losses.append(testloss)\n",
    "    test_fold_accuracies.append(testacc)\n",
    "    test_fold_recall.append(testrec)\n",
    "    test_fold_precision.append(testprec)\n",
    "    test_fold_ious.append(testiou_score)\n",
    "\n",
    "    valid_fold_losses.append(validloss)\n",
    "    valid_fold_accuracies.append(validacc)\n",
    "    valid_fold_recall.append(validrec)\n",
    "    valid_fold_precision.append(validprec)\n",
    "    valid_fold_ious.append(validiou_score)\n",
    "\n",
    "# ✅ Print Final Results\n",
    "print(\"\\n✅ Final 5-Fold Cross-Validation Evaluation:\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_fold_accuracies):.3f} ± {np.std(test_fold_accuracies):.3f}\")\n",
    "print(f\"Average Test Recall: {np.mean(test_fold_recall):.3f} ± {np.std(test_fold_recall):.3f}\")\n",
    "print(f\"Average Test Precision: {np.mean(test_fold_precision):.3f} ± {np.std(test_fold_precision):.3f}\")\n",
    "print(f\"Average Test IoU: {np.mean(test_fold_ious):.3f} ± {np.std(test_fold_ious):.3f}\")\n",
    "print(f\"Average Test Loss: {np.mean(test_fold_losses):.3f} ± {np.std(test_fold_losses):.3f}\")\n",
    "\n",
    "print(f\"Average Valid Accuracy: {np.mean(valid_fold_accuracies):.3f} ± {np.std(valid_fold_accuracies):.3f}\")\n",
    "print(f\"Average Valid Recall: {np.mean(valid_fold_recall):.3f} ± {np.std(valid_fold_recall):.3f}\")\n",
    "print(f\"Average Valid Precision: {np.mean(valid_fold_precision):.3f} ± {np.std(valid_fold_precision):.3f}\")\n",
    "print(f\"Average Valid IoU: {np.mean(valid_fold_ious):.3f} ± {np.std(valid_fold_ious):.3f}\")\n",
    "print(f\"Average Valid Loss: {np.mean(valid_fold_losses):.3f} ± {np.std(valid_fold_losses):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e74a90-5d8a-47f5-bad1-762cb7a34c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quantitative_heatmap_grid(heatmap_matrix, layer_name, save_path, step=16):\n",
    "    # Downsample to make values readable\n",
    "    grid_data = heatmap_matrix[::step, ::step]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(grid_data, annot=True, fmt=\".2f\", cmap=\"viridis\", \n",
    "                xticklabels=False, yticklabels=False, cbar=True, square=True)\n",
    "    plt.title(f\"Quantitative Heatmap - {layer_name}\")\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(save_path, dpi=300)\n",
    "    #plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879ff7d-9b07-4d85-9ccb-050728a63bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(kf.split(images)):\n",
    "    print(f\"\\n🔹 Predicting on Fold {fold + 1}/5\")\n",
    "\n",
    "    test_x_fold, test_y_fold = images[test_idx], masks[test_idx]  # Get test images/masks for the current fold\n",
    "\n",
    "    model = models[fold]  # Load corresponding trained model\n",
    "\n",
    "    for x_path, y_path in tqdm(zip(test_x_fold, test_y_fold), total=len(test_x_fold)):\n",
    "        fname = os.path.basename(x_path)\n",
    "        tname = fname.rsplit('.', 1)[0]\n",
    "        output_path = os.path.join(output_dir, tname)\n",
    "        x, rgb_img = read_image_predict(x_path)\n",
    "        y = read_mask_predict(y_path)\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
    "    \n",
    "        conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "        for i, layer in enumerate(conv_layers):\n",
    "            #print(f\"Layer {i}: {layer.name}, Output Shape: {layer.output_shape}\")\n",
    "            heatmap = generate_heatmap(model, x, layer.name)\n",
    "\n",
    "            # Display heatmap for the current layer\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(heatmap)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Heatmap from Layer: {layer.name}\")\n",
    "            \n",
    "            # Show each heatmap separately\n",
    "            plt.show()\n",
    "\n",
    "            quant_path = os.path.join(output_path, f\"{layer.name}_quant_heatmap.png\")\n",
    "            generate_quantitative_heatmap_grid(cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY) / 255.0, layer.name, quant_path)\n",
    "            \n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ffafd-b2d1-4a5e-8cad-85d2f0179474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(images)):\n",
    "    print(f\"\\n🔹 Predicting on Fold {fold + 1}/5\")\n",
    "\n",
    "    test_x_fold, test_y_fold = images[test_idx], masks[test_idx]  # Get test images/masks for the current fold\n",
    "\n",
    "    model = models[fold]  # Load corresponding trained model\n",
    "\n",
    "    for x_path, y_path in tqdm(zip(test_x_fold, test_y_fold), total=len(test_x_fold)):\n",
    "        x, rgb_img = read_image_predict(x_path)\n",
    "        y = read_mask_predict(y_path)\n",
    "\n",
    "        # ✅ Make Prediction\n",
    "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
    "\n",
    "        # ✅ Resize prediction to original dimensions (width=788, height=510)\n",
    "        y_pred_resized = cv2.resize(y_pred, (original_width, original_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "        \n",
    "        y_pred_resized = keep_largest_component(y_pred_resized)\n",
    "        \n",
    "        # ✅ Remove channel dimension if present\n",
    "        if y_pred_resized.ndim == 3:\n",
    "            y_pred_resized = np.squeeze(y_pred_resized, axis=-1)\n",
    "        \n",
    "        # Save spot\n",
    "        fname = os.path.basename(x_path)\n",
    "        output_path = os.path.join(pred_output_dir, fname)\n",
    "\n",
    "        pred_uint8 = cv2.normalize(y_pred_resized, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "        cv2.imwrite(output_path, pred_uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b90c38-f187-4de5-b244-8a26740e566e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_inference(save_ensemble=False):\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\n🔹 Predicting on Fold {fold + 1}/5\")\n",
    "\n",
    "        test_x_fold, test_y_fold = images[test_idx], masks[test_idx]\n",
    "        model = models[fold]\n",
    "        model = enable_dropout(model)\n",
    "\n",
    "        for x_path, y_path in tqdm(zip(test_x_fold, test_y_fold), total=len(test_x_fold)):\n",
    "            x, rgb_img = read_image_predict(x_path)\n",
    "            y = read_mask_predict(y_path)\n",
    "            fname = os.path.basename(x_path)\n",
    "            tname = fname.rsplit('.', 1)[0]\n",
    "\n",
    "            # Generate MC predictions (50 samples)\n",
    "            mc_predictions = np.stack([\n",
    "                model(np.expand_dims(x, axis=0), training=True)[0].numpy()\n",
    "                for _ in range(50)\n",
    "            ], axis=0)  # (50, 256, 256, 1)\n",
    "\n",
    "            # Compute all uncertainty metrics\n",
    "            mean_pred, uncertainty_map = monte_carlo_predictions(model, x, n_samples=50)\n",
    "            p_entropy, e_entropy, mi, var = compute_uncertainty_metrics(mc_predictions)\n",
    "\n",
    "            # Post-process prediction\n",
    "            mean_pred_calibrated = calibrate_predictions(mean_pred, calibrator)\n",
    "\n",
    "            calibrated_pred_resized = cv2.normalize(mean_pred_calibrated, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            calibrated_pred_resized = calibrated_pred_resized.astype(np.uint8)\n",
    "      \n",
    "            calibrated_pred_resized = cv2.resize(\n",
    "                calibrated_pred_resized.astype(np.uint8), (788, 510), interpolation=cv2.INTER_LANCZOS4\n",
    "            )\n",
    "\n",
    "            processed_pred_resized = keep_largest_components(calibrated_pred_resized, threshold=70)\n",
    "\n",
    "\n",
    "            # ✅ Remove channel dimension if present\n",
    "            if processed_pred_resized.ndim == 3:\n",
    "                processed_pred_resized = np.squeeze(processed_pred_resized, axis=-1)\n",
    "            \n",
    "            if save_ensemble:\n",
    "                output_path = os.path.join(pred_output_dir, f\"{tname}.bmp\")\n",
    "                cv2.imwrite(output_path, processed_pred_resized)\n",
    "                continue\n",
    "\n",
    "            mu = calculate_mu(uncertainty_map)\n",
    "            ruv = calculate_ruv(uncertainty_map)\n",
    "\n",
    "            # 🧠 Print numerical summaries\n",
    "            print(f\"\\n{tname}\")\n",
    "            print(f\"Mean Uncertainty (MU): {mu}\")\n",
    "            print(f\"Region Uncertainty Volume (RUV): {ruv}\")\n",
    "            print(f\"Mean Mutual Information: {np.mean(mi):.4f}\")\n",
    "            print(f\"Predictive Entropy Mean: {np.mean(p_entropy):.4f}\")\n",
    "            print(f\"Variance (Std Dev²) Mean: {np.mean(var):.4f}\")\n",
    "\n",
    "            # 🔍 Show predictions\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(processed_pred_resized.squeeze(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Resized Processed Prediction\")\n",
    "            plt.show()\n",
    "\n",
    "            y_mask_gt = cv2.imread(y_path, cv2.IMREAD_GRAYSCALE)\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(y_mask_gt, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Ground Truth mask\")\n",
    "            plt.show()\n",
    "            \n",
    "            # Display heatmap for the current layer\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(mean_pred)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Mean prediction map\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(uncertainty_map)\n",
    "            #plt.imshow(uncertainty_map, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"uncertainty prediction map\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(mi, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Mutual Information (Epistemic)\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(p_entropy, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Predictive Entropy\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(var, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Variance (Std Dev²)\")\n",
    "            plt.show()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69331f65-cd93-4685-ac87-ea9983d573f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8a487-6ed6-423c-9c70-ab83ec5b497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference(save_ensemble=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe15b8e-f46b-4ead-8dbb-988fd8032464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(nfolds=5, nensembles=5, save_ensemble=False, mod=\"\", manual_segment_this_path=None):\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\n🔹 Predicting on Fold {fold + 1}/5\")\n",
    "        test_x_fold, test_y_fold = images[test_idx], masks[test_idx]\n",
    "\n",
    "        ensemble_models = []\n",
    "        for model_num in range(1, nensembles+1):\n",
    "            model_string = mod.format(fold+1, model_num)\n",
    "            m = tf.keras.models.load_model(model_string, custom_objects={\"iou\": iou, \"log_dice_bce_loss\": log_dice_bce_loss})\n",
    "            m = enable_dropout(m)\n",
    "            ensemble_models.append(m)\n",
    "        \n",
    "        for x_path, y_path in tqdm(zip(test_x_fold, test_y_fold), total=len(test_x_fold)):\n",
    "            \n",
    "            if manual_segment_this_path is not None:\n",
    "                if manual_segment_this_path != x_path:\n",
    "                    continue\n",
    "            \n",
    "            x, rgb_img = read_image_predict(x_path)\n",
    "            y = read_mask_predict(y_path)\n",
    "            fname = os.path.basename(x_path)\n",
    "            tname = fname.rsplit('.', 1)[0]\n",
    "\n",
    "            mcpreds = []\n",
    "            meanpreds = []\n",
    "            uncmaps = []\n",
    "\n",
    "            for model in ensemble_models:\n",
    "                # Generate MC predictions (50 samples)\n",
    "                mc_predictions = np.stack([\n",
    "                    model(np.expand_dims(x, axis=0), training=True)[0].numpy()\n",
    "                    for _ in range(50)\n",
    "                ], axis=0)  # (50, 256, 256, 1)\n",
    "\n",
    "                # Compute all uncertainty metrics\n",
    "                mean_pred, uncertainty_map = monte_carlo_predictions(model, x, n_samples=50)\n",
    "                \n",
    "                mcpreds.append(mc_predictions)\n",
    "                meanpreds.append(mean_pred)\n",
    "                uncmaps.append(uncertainty_map)\n",
    "\n",
    "            # Final ensemble average across models\n",
    "            mc_preds_all = np.stack(mcpreds, axis=0)      # (n_models, 50, 256, 256, 1)\n",
    "            mean_preds_all = np.stack(meanpreds, axis=0)   # (n_models, 256, 256, 1)\n",
    "            uncmaps_all = np.stack(uncmaps, axis=0)    # (n_models, 256, 256, 1)\n",
    "\n",
    "            mean_mc_ensemble = mc_preds_all.mean(axis=(0,1))        # (256, 256, 1)\n",
    "            mean_pred_ensemble = mean_preds_all.mean(axis=0)          # (256, 256, 1)\n",
    "            mean_uncmap_ensemble = uncmaps_all.mean(axis=0)           # (256, 256, 1)\n",
    "\n",
    "            p_entropy, e_entropy, mi, var = compute_uncertainty_metrics(mc_preds_all.mean(axis=0))\n",
    "\n",
    "            # Post-process prediction\n",
    "            mean_pred_calibrated = calibrate_predictions(mean_pred_ensemble, calibrator)\n",
    "\n",
    "            calibrated_pred_resized = cv2.normalize(mean_pred_calibrated, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            calibrated_pred_resized = calibrated_pred_resized.astype(np.uint8)\n",
    "      \n",
    "            calibrated_pred_resized = cv2.resize(\n",
    "                calibrated_pred_resized.astype(np.uint8), (788, 510), interpolation=cv2.INTER_LANCZOS4\n",
    "            )\n",
    "\n",
    "            processed_pred_resized = keep_largest_components(calibrated_pred_resized, threshold=70)\n",
    "\n",
    "            if manual_segment_this_path is not None:\n",
    "                processed_pred_resized = keep_largest_components(calibrated_pred_resized, threshold=30, component_rank=2)\n",
    "\n",
    "\n",
    "            # ✅ Remove channel dimension if present\n",
    "            if processed_pred_resized.ndim == 3:\n",
    "                processed_pred_resized = np.squeeze(processed_pred_resized, axis=-1)\n",
    "            \n",
    "            if save_ensemble:\n",
    "                output_path = os.path.join(pred_output_dir, f\"{tname}.bmp\")\n",
    "                cv2.imwrite(output_path, processed_pred_resized)\n",
    "                continue\n",
    "\n",
    "            mu = calculate_mu(mean_uncmap_ensemble)\n",
    "            ruv = calculate_ruv(mean_uncmap_ensemble)\n",
    "\n",
    "            # 🧠 Print numerical summaries\n",
    "            print(f\"\\n{tname}\")\n",
    "            print(f\"Mean Uncertainty (MU): {mu}\")\n",
    "            print(f\"Region Uncertainty Volume (RUV): {ruv}\")\n",
    "            print(f\"Mean Mutual Information: {np.mean(mi):.4f}\")\n",
    "            print(f\"Predictive Entropy Mean: {np.mean(p_entropy):.4f}\")\n",
    "            print(f\"Variance (Std Dev²) Mean: {np.mean(var):.4f}\")\n",
    "\n",
    "            # 🔍 Show predictions\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(processed_pred_resized.squeeze(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Resized Processed Prediction\")\n",
    "            plt.show()\n",
    "\n",
    "            y_mask_gt = cv2.imread(y_path, cv2.IMREAD_GRAYSCALE)\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(y_mask_gt, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Ground Truth mask\")\n",
    "            plt.show()\n",
    "            \n",
    "            # Display heatmap for the current layer\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(mean_pred_ensemble)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Mean prediction map\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(mean_uncmap_ensemble)\n",
    "            #plt.imshow(mean_uncmap_ensemble, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"uncertainty prediction map\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(mi, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Mutual Information (Epistemic)\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(p_entropy, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Predictive Entropy\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(var, cmap='hot')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Variance (Std Dev²)\")\n",
    "            plt.show()\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89201867-46db-48fe-8e87-da95662a97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ensemble(save_ensemble=True, mod=\"XBoundNet_{}Fold_LDL07_BCE03_Drop02onlowres_Lre4_ensemble_model_{}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d7221-7511-4bee-93da-9b0da0b8561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_path = r\"/path/to/dataset/Images/Pt 0057 - RA - TestID20240223131548--02-2812-45-35.bmp\"\n",
    "#predict_ensemble(save_ensemble=False, mod=\"XBoundNet_{}Fold_LDL07_BCE03_Drop02onlowres_Lre4_ensemble_model_{}.h5\", manual_segment_this_path=manual_path)\n",
    "predict_ensemble(save_ensemble=True, mod=\"XBoundNet_{}Fold_LDL07_BCE03_Drop02onlowres_Lre4_ensemble_model_{}.h5\", manual_segment_this_path=manual_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3741e64-665e-4e34-b943-d7043579a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ensemble(nfolds=5, nensembles=5, mod=\"\", show_final=True, show_conv_layers=False, show_thresholds=False, show_uncertainty=False):\n",
    "    # Iterate through test images\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\n🔹 Predicting on Fold {fold + 1}/5\")\n",
    "    \n",
    "        test_x_fold, test_y_fold = images[test_idx], masks[test_idx]  # Get test images/masks for the current fold\n",
    "    \n",
    "        ensemble_models = []\n",
    "        for model_num in range(1, nensembles+1):\n",
    "            model_string = mod.format(fold+1, model_num)\n",
    "            m = tf.keras.models.load_model(model_string, custom_objects={\"iou\": iou, \"log_dice_bce_loss\": log_dice_bce_loss})\n",
    "            m = enable_dropout(m)\n",
    "            ensemble_models.append(m)\n",
    "    \n",
    "        for x_path, y_path in tqdm(zip(test_x_fold, test_y_fold), total=len(test_x_fold)):\n",
    "            fname = os.path.basename(x_path)\n",
    "            tname = fname.rsplit('.', 1)[0]\n",
    "            #if (tname != \"Pt 0006 - RA - TestID20240221154926--02-2810-21-39\"):\n",
    "             #   continue\n",
    "            output_path = os.path.join(output_dir, tname)\n",
    "            print(\"saving to: \" + output_path)\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            #tname = \"test_\" + tname\n",
    "            x, rgb_img = read_image_predict(x_path)\n",
    "            y = read_mask_predict(y_path)\n",
    "            x_normalized = normalize_img(x_path)\n",
    "\n",
    "            mcpreds = []\n",
    "            meanpreds = []\n",
    "            uncmaps = []\n",
    "\n",
    "            for model in ensemble_models:\n",
    "                # Generate MC predictions (50 samples)\n",
    "                mc_predictions = np.stack([\n",
    "                    model(np.expand_dims(x, axis=0), training=True)[0].numpy()\n",
    "                    for _ in range(50)\n",
    "                ], axis=0)  # (50, 256, 256, 1)\n",
    "\n",
    "                # Compute all uncertainty metrics\n",
    "                mean_pred, uncertainty_map = monte_carlo_predictions(model, x, n_samples=50)\n",
    "                \n",
    "                mcpreds.append(mc_predictions)\n",
    "                meanpreds.append(mean_pred)\n",
    "                uncmaps.append(uncertainty_map)\n",
    "\n",
    "            # Final ensemble average across models\n",
    "            mc_preds_all = np.stack(mcpreds, axis=0)      # (n_models, 50, 256, 256, 1)\n",
    "            mean_preds_all = np.stack(meanpreds, axis=0)   # (n_models, 256, 256, 1)\n",
    "            uncmaps_all = np.stack(uncmaps, axis=0)    # (n_models, 256, 256, 1)\n",
    "\n",
    "            mean_mc_ensemble = mc_preds_all.mean(axis=(0,1))        # (256, 256, 1)\n",
    "            mean_pred_ensemble = mean_preds_all.mean(axis=0)          # (256, 256, 1)\n",
    "            mean_uncmap_ensemble = uncmaps_all.mean(axis=0)           # (256, 256, 1)\n",
    "\n",
    "            p_entropy, e_entropy, mi, var = compute_uncertainty_metrics(mc_preds_all.mean(axis=0))\n",
    "\n",
    "            # Post-process prediction\n",
    "            mean_pred_calibrated = calibrate_predictions(mean_pred_ensemble, calibrator)\n",
    "\n",
    "            calibrated_pred = cv2.normalize(mean_pred_calibrated, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            calibrated_pred = calibrated_pred.astype(np.uint8)\n",
    "      \n",
    "            processed_pred_resized = keep_largest_components(calibrated_pred, threshold=60)\n",
    "\n",
    "            binary_gt = (y > 127).astype(np.uint8).squeeze()\n",
    "            binary_pred = (processed_pred_resized > 127).astype(np.uint8).squeeze()\n",
    "            \n",
    "            overlays = overlay_uncertainty_mask(rgb_img, binary_pred, binary_gt, p_entropy, thresholds=[100, 75, 50, 25])\n",
    "            \n",
    "            for th, vis in overlays:\n",
    "                tmp_path = os.path.join(output_path, f\"Threshold_{th}.bmp\")\n",
    "                cv2.imwrite(tmp_path, vis)\n",
    "                if show_thresholds:\n",
    "                    plt.figure(figsize=(5, 5))\n",
    "                    plt.imshow(vis)\n",
    "                    plt.title(f\"Threshold {th}\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.show()\n",
    "\n",
    "        \n",
    "            conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "            for i, layer in enumerate(conv_layers):\n",
    "                #print(f\"Layer {i}: {layer.name}, Output Shape: {layer.output_shape}\")\n",
    "                heatmap = generate_heatmap(model, x, layer.name)\n",
    "    \n",
    "                if show_conv_layers:\n",
    "                    # Display heatmap for the current layer\n",
    "                    plt.figure(figsize=(6, 6))\n",
    "                    plt.imshow(heatmap)\n",
    "                    plt.axis('off')\n",
    "                    plt.title(f\"Heatmap from Layer: {layer.name}\")\n",
    "                    \n",
    "                    # Show each heatmap separately\n",
    "                    plt.show()\n",
    "        \n",
    "                # Convert heatmap to uint8 (0-255) for saving\n",
    "                #heatmap_uint8 = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "    \n",
    "                overlay_result = overlay_dual_mask_boundary(heatmap, mask_parse(y), mask_parse(binary_pred))\n",
    "                tmp_path = os.path.join(output_path, f\"{layer.name}_with_contour.bmp\")\n",
    "                cv2.imwrite(tmp_path, overlay_result)     \n",
    "                tmp_path = os.path.join(output_path, f\"{layer.name}.bmp\")\n",
    "                cv2.imwrite(tmp_path, heatmap)\n",
    "                    \n",
    "    \n",
    "            tmp_path = os.path.join(output_path, \"original_image.bmp\")\n",
    "            og_uint8 = cv2.normalize(rgb_img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            cv2.imwrite(tmp_path, og_uint8) \n",
    "        \n",
    "            tmp_path = os.path.join(output_path, \"groundtruth_mask.bmp\")\n",
    "            cv2.imwrite(tmp_path, y)\n",
    "        \n",
    "            tmp_path = os.path.join(output_path, \"predicted_mask.bmp\")\n",
    "            cv2.imwrite(tmp_path, processed_pred_resized)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"mean_prediction_map.bmp\")\n",
    "            pred_map_uint8 = cv2.normalize(mean_pred_ensemble.squeeze(), None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_pred = cv2.applyColorMap(pred_map_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_pred)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"uncertainty_map.bmp\")\n",
    "            uncert_map_uint8 = cv2.normalize(mean_uncmap_ensemble, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_uncert = cv2.applyColorMap(uncert_map_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_uncert)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"Mutual_Information_(Epistemic).bmp\")\n",
    "            mi_uint8 = cv2.normalize(mi, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_mi = cv2.applyColorMap(mi_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_mi)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"Predictive_Entropy.bmp\")\n",
    "            p_entropy_uint8 = cv2.normalize(p_entropy, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_pe = cv2.applyColorMap(p_entropy_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_pe)\n",
    "\n",
    "            tmp_path = os.path.join(output_path, \"Variance.bmp\")\n",
    "            var_uint8 = cv2.normalize(var, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            colored_var = cv2.applyColorMap(var_uint8, cv2.COLORMAP_INFERNO)\n",
    "            cv2.imwrite(tmp_path, colored_var)\n",
    "            \n",
    "            contour_result_on_original = overlay_dual_mask_boundary(x_normalized, mask_parse(y), mask_parse(binary_pred))\n",
    "            tmp_path = os.path.join(output_path, \"contour_result_on_original.bmp\")\n",
    "            cont_uint8 = cv2.normalize(contour_result_on_original, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "            cv2.imwrite(tmp_path, cont_uint8)\n",
    "\n",
    "            prediction_over_img = binary_mask_overlay(processed_pred_resized.squeeze(), x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"prediction_over_img.bmp\")\n",
    "            cv2.imwrite(tmp_path, prediction_over_img)\n",
    "\n",
    "            mask_over_img = binary_mask_overlay(y.squeeze(), x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"mask_over_img.bmp\")\n",
    "            cv2.imwrite(tmp_path, mask_over_img)\n",
    "\n",
    "            heatmap_over_image = heatmap_overlay(pred_map_uint8, x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"heatmap_over_image.bmp\")\n",
    "            cv2.imwrite(tmp_path, heatmap_over_image)\n",
    "\n",
    "            uncertainty_over_image = heatmap_overlay(uncert_map_uint8, x_normalized)\n",
    "            tmp_path = os.path.join(output_path, \"uncertainty_over_image.bmp\")\n",
    "            cv2.imwrite(tmp_path, uncertainty_over_image)\n",
    "                        \n",
    "            if show_uncertainty:\n",
    "                # 🔍 Show predictions\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(processed_pred_resized.squeeze(), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Processed Prediction\")\n",
    "                plt.show()\n",
    "                \n",
    "                # Display heatmap for the current layer\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(mean_pred_ensemble)\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Mean prediction map\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                #plt.imshow(uncertainty_map)\n",
    "                plt.imshow(mean_uncmap_ensemble, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"uncertainty prediction map\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(mi, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Mutual Information (Epistemic)\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(p_entropy, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Predictive Entropy\")\n",
    "                plt.show()\n",
    "    \n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(var, cmap='hot')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Variance (Std Dev²)\")\n",
    "                plt.show()\n",
    "            \n",
    "            if show_final:\n",
    "\n",
    "                # Normalize grayscale base\n",
    "                base_gray = x_normalized.astype(np.float32)\n",
    "                base_gray -= base_gray.min()\n",
    "                base_gray /= (base_gray.max() + 1e-8)\n",
    "            \n",
    "                fig, axes = plt.subplots(1, 5, figsize=(32, 5))\n",
    "            \n",
    "                # 1. Original Image\n",
    "                axes[0].imshow(base_gray, cmap='gray')  # Ensure grayscale colormap is used\n",
    "                axes[0].set_title(f\"Original Image: {tname}\")\n",
    "                axes[0].axis(\"off\")\n",
    "            \n",
    "                # 2. Ground Truth Mask\n",
    "                axes[1].imshow(base_gray, cmap='gray')\n",
    "                gt_mask = np.ma.masked_where(binary_gt == 0, binary_gt)\n",
    "                axes[1].imshow(gt_mask, cmap='spring', alpha=0.25)\n",
    "                axes[1].set_title(\"Annotated Mask over Image\")\n",
    "                axes[1].axis(\"off\")\n",
    "            \n",
    "                # 3. Predicted Mask\n",
    "                axes[2].imshow(base_gray, cmap='gray')\n",
    "                pred_mask = np.ma.masked_where(binary_pred == 0, binary_pred)\n",
    "                axes[2].imshow(pred_mask, cmap='winter', alpha=0.25)\n",
    "                axes[2].set_title(\"Predicted Mask over Image\")\n",
    "                axes[2].axis(\"off\")\n",
    "                            \n",
    "                # 4. Probability Map Overlay\n",
    "                axes[3].imshow(base_gray, cmap='gray')\n",
    "                mean_mask = np.ma.masked_where(mean_pred_ensemble <= 0.001, mean_pred_ensemble)\n",
    "                im3 = axes[3].imshow(mean_mask, cmap='magma', alpha=0.25)\n",
    "                axes[3].set_title(\"Probability over Image\")\n",
    "                axes[3].axis(\"off\")\n",
    "                cbar = fig.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "                cbar.set_label(\"Probability\", rotation=270, labelpad=15)\n",
    "            \n",
    "                # 5. Uncertainty Map Overlay\n",
    "                axes[4].imshow(base_gray, cmap='gray')\n",
    "                uncert_mask = np.ma.masked_where(mean_uncmap_ensemble <= 0.03, mean_uncmap_ensemble)\n",
    "                im4 = axes[4].imshow(uncert_mask, cmap='magma', alpha=0.25)\n",
    "                axes[4].set_title(\"Uncertainty over Image\")\n",
    "                axes[4].axis(\"off\")\n",
    "                cbar = fig.colorbar(im4, ax=axes[4], fraction=0.046, pad=0.04)\n",
    "                cbar.set_label(\"Uncertainty\", rotation=270, labelpad=15)\n",
    "            \n",
    "                # Save\n",
    "                tmp_path = os.path.join(output_path, \"output_side_to_side.png\")\n",
    "                plt.savefig(tmp_path, bbox_inches=\"tight\", dpi=600)\n",
    "                plt.tight_layout()\n",
    "                #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abe59e-8499-4664-a6a9-cffe6b21cc19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ensemble(mod=\"XBoundNet_{}Fold_LDL07_BCE03_Drop02onlowres_Lre4_ensemble_model_{}.h5\", show_final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330bd44-a233-4e86-bab2-7eb2076d7b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
